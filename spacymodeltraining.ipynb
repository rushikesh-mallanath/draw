{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6BkzB5+dnOa/zNI3Yj9W4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rushikesh-mallanath/draw/blob/main/spacymodeltraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HWdMRJaunen2"
      },
      "outputs": [],
      "source": [
        "pip install -U spacy -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPn5q1h2wDQn",
        "outputId": "1c2e942c-878a-42c5-f40c-5c8969f1e8cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-21 08:01:21.389006: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-21 08:01:22.220324: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[1m\n",
            "============================== Info about spaCy ==============================\u001b[0m\n",
            "\n",
            "spaCy version    3.6.1                         \n",
            "Location         /usr/local/lib/python3.10/dist-packages/spacy\n",
            "Platform         Linux-5.15.120+-x86_64-with-glibc2.35\n",
            "Python version   3.10.12                       \n",
            "Pipelines        en_core_web_sm (3.6.0)        \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qJWrol-wedr",
        "outputId": "26fb0427-87ef-419b-9f36-be377eb58997"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-21 08:02:49.960950: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-21 08:02:50.770183: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-lg==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.6.0/en_core_web_lg-3.6.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.1.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuFIq3Uyw06P",
        "outputId": "f41e2b00-459e-4ce5-a68b-ff370d152c58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-21 08:04:49.840713: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-21 08:04:51.219189: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[1m\n",
            "============================== Info about spaCy ==============================\u001b[0m\n",
            "\n",
            "spaCy version    3.6.1                         \n",
            "Location         /usr/local/lib/python3.10/dist-packages/spacy\n",
            "Platform         Linux-5.15.120+-x86_64-with-glibc2.35\n",
            "Python version   3.10.12                       \n",
            "Pipelines        en_core_web_lg (3.6.0), en_core_web_sm (3.6.0)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "db = DocBin()"
      ],
      "metadata": {
        "id": "fr9N1WWRxR8B"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "f = open('training_data.json')\n",
        "TRAIN_DATA = json.load(f)"
      ],
      "metadata": {
        "id": "LQl8R_fqyNiF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text, annot in tqdm(TRAIN_DATA['annotations']):\n",
        "  doc = nlp.make_doc(text)\n",
        "  ents = []\n",
        "  for start, end, label in annot[\"entities\"]:\n",
        "    span = doc.char_span(start, end, label = label, alignment_mode=\"contract\")\n",
        "    if span is None:\n",
        "      print(\"Skipping entity\")\n",
        "    else:\n",
        "      ents.append(span)\n",
        "  doc.ents = ents\n",
        "  db.add(doc)\n",
        "\n",
        "db.to_disk(\"/content/training_data.spacy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FianC2My_Wi",
        "outputId": "73c62d7a-e0bf-4e57-84e8-2f6a2f3ff258"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 44.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wHmu2Fm2FeUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init config config.cfg --lang en --pipeline ner --optimize accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_4oLEvO0KP5",
        "outputId": "1062ba7b-356c-43e2-b723-ece64138363a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-21 08:22:24.658209: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
            "install the spacy-transformers package and re-run this command. The config\n",
            "generated now does not use transformers.\u001b[0m\n",
            "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
            "- Language: en\n",
            "- Pipeline: ner\n",
            "- Optimize for: accuracy\n",
            "- Hardware: CPU\n",
            "- Transformer: None\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./training_data.spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWBjvAMR1TWg",
        "outputId": "c0622e2e-a851-4cbf-b4b5-522d108ffb05"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-21 09:39:09.233530: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00   1302.23    0.00    0.00    0.00    0.00\n",
            " 33     200       5655.71  18075.42   89.09   89.09   89.09    0.89\n",
            " 66     400         12.48    132.06  100.00  100.00  100.00    1.00\n",
            "100     600          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "133     800          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "166    1000          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "200    1200        482.92    675.17  100.00  100.00  100.00    1.00\n",
            "233    1400         91.50    146.98  100.00  100.00  100.00    1.00\n",
            "266    1600          2.10      2.80  100.00  100.00  100.00    1.00\n",
            "300    1800          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "333    2000          0.18      0.20  100.00  100.00  100.00    1.00\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h6QbAus8Fpa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"/content/model-best\")"
      ],
      "metadata": {
        "id": "ae5ImJ5iPTmg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG41qHwiPcTF",
        "outputId": "603ed9a4-20c1-4647-fc47-84607da66833"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.23.3-cp310-none-manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/4.3 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m3.1/4.3 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.3 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.23.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.23.3 PyMuPDFb-1.23.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, fitz\n",
        "import os\n",
        "\n",
        "fname = '/content/resume.pdf'\n",
        "mydoc = fitz.open(fname)"
      ],
      "metadata": {
        "id": "hMgaxvMZPpRp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \"\n",
        "for page in mydoc:\n",
        "    text = text + str(page.get_text())"
      ],
      "metadata": {
        "id": "Y8WfSj-aP74X"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "TIuISUzwRfDG",
        "outputId": "325d6f71-022f-47b6-9531-09aeb10f7c4a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Omkar Pathak\\nSOFTWARE ENGINEER · FULL STACK PYTHON DEVELOPER\\nPune, Maharashtra, India\\n\\uf10b (+91) 8087996634\\n|\\n\\uf0e0 omkarpathak27@gmail.com\\n|\\n\\uf015 www.omkarpathak.in\\n|\\n\\uf092 OmkarPathak\\n|\\n\\uf08c omkar-pathak-94473811b\\n“Make the change that you want to see in the world.”\\nExperience\\nSchlumberger\\nPune, Maharashtra, India\\nDATA ENGINEER\\nJuly 2018 - Present\\n• Responsible for implementing and managing an end-to-end CI/CD Pipeline with custom validations for Informatica migrations which\\nbrought migration time to 1.5 hours from 9 hours without any manual intervention\\n• Enhancing, auditing and maintaining custom data ingestion framework that ingest around 1TB of data each day to over 70 business\\nunits\\n• Working with L3 developer team to ensure the discussed Scrum PBI’s are delivered on time for data ingestions\\n• Planning and Executing QA and Production Release Cycle activities\\nTruso\\nPune, Maharashtra, India\\nFULL STACK DEVELOPER INTERN\\nJune 2018 - July 2018\\n• Created RESTful apis\\n• Tried my hands on Angular 5/6\\n• Was responsible for Django backend development\\nPropeluss\\nPune, Maharashtra, India\\nDATA ENGINEERING INTERN\\nOctober 2017 - January 2018\\n• Wrote various automation scripts to scrape data from various websites.\\n• Applied Natural Language Processing to articles scraped from the internet to extract different entities in these articles using entity\\nextraction algorithms and applying Machine Learning to classify these articles.\\n• Also applied KNN with LSA for extracting relevant tags for various startups based on their works.\\nGeeksForGeeks\\nPune, Maharashtra, India\\nTECHNICAL CONTENT WRITER\\nJuly 2017 - September 2017\\n• Published 4 articles for the topics such as Data Structures and Algorithms and Python\\nSofttestlab Technologies\\nPune, Maharashtra, India\\nWEB DEVELOPER INTERN\\nJune 2017 - July 2017\\n• Was responsible for creating an internal project for the company using PHP and Laravel for testing purposes\\n• Worked on a live project for creating closure reports using PHP and Excel\\nProjects\\nPyresparser\\nAPI/Python Package\\nPERSONAL PROJECT\\nJuly 2019 - Present\\n• A simple resume parser used for extracting information from resumes\\n• Extract information from thousands of resumes in just a few seconds\\n• Author and maintainer of this project\\nGarbage Level Monitoring System\\nIoT\\nTEAM PROJECT\\nOctober 2017 - May 2018\\n• To find a economical and smarter alternative to current garbage problems\\n• Users can monitor levels of all garbage bins from a global dashboard provided\\n• Was responsible for Django backend development\\nNOVEMBER 3, 2019\\nOMKAR PATHAK · RÉSUMÉ\\n1\\nPygorithm\\nAPI / Python Package\\nPERSONAL PROJECT\\nJuly 2017 - Present\\n• Author and maintainer of this project\\n• An educational library to teach all the major algorithms\\n• Got covered in Fosstack, FullStackFeed, Kleiber and Tagged under Hotest Github Project on ITCodeMonkey\\nSmart Surveillance System using Raspberry Pi and Face Recognition\\nIoT\\nPERSONAL PROJECT\\nJanuary 2017 - February 2017\\n• Face Recognition using OpenCV and Python\\n• Raspberry Pi was used as the data server\\n• User notified if any suspicious activity detected in real time\\nPassword Strength Evaluator using Machine Learning\\nMachine Learning\\nPERSONAL PROJECT\\nMarch 2017\\n• SVM algorithm used for training and classification\\n• Flask framework used\\n• Self-generated dataset\\nEducation\\nMarathwada Mitra Mandal’s College of Engineering\\nPune, Maharashtra, India\\nB.E. IN COMPUTER ENGINEERING\\n2014 - 2018\\n• Aggregate 74%\\nSkills\\nProgramming Languages:\\nPython, C, PHP, C++, Shell Script\\nFrontend Technologies:\\nHTML, CSS, JavaScript, Angular 6/7\\nBackend Technologies:\\nDjango, Flask (Python), Laravel (PHP)\\nOperating Systems:\\nLinux, Unix, Windows\\nDatabases:\\nMySQL, SQLite, MongoDB\\nOther:\\nGit, NLP, Scikit-Learn, OpenCV, Cloud (GCP, Azure, DigitalOcean)\\nHonors & Awards\\n2018\\nTop rated Python developer, in Pune and Fifth in India at Github\\nIndia\\n2018\\nQuora Top Writer,\\nIndia\\n2018\\nAwarded ‘The Best Outgoing Student Award 2017-18’,\\nMMCOE, Pune\\n2018\\nWon 2nd Prize, in an Hackathon organized by MIT-ADT Persona Fest 2018\\nPune\\n2018\\nBest Paper Award, in National Level Conference on “Emerging Trends in Computing , Analytics\\nand Security - 2018”(NCETCAS-2018)\\nMMCOE, Pune\\nExtracurricular Activities\\nContributor in Pune PyCon 2018\\nPUNE, MAHARASHTRA, INDIA\\n2018\\n• Was a part of Website Designing and volunteering committee\\nNOVEMBER 3, 2019\\nOMKAR PATHAK · RÉSUMÉ\\n2\\nMentor at GirlScript Summer of Code 2019\\nPUNE, MAHARASHTRA, INDIA\\n2019\\n• Mentored 4+ teams in various domains\\nOrganizing head for the National level technical event -\\nInnovatus\\nPUNE, MAHARASHTRA, INDIA\\n2018\\n• Organized project competitions\\nWorkshop on IoT and Python\\nMMCOE, PUNE\\n10 Jan 2017\\n• Conducted a workshop for second year students to give them a brief overview about IoT by completing three mini projects and taught\\nthem basics of Python programming language\\nPublications\\nSmart Surveillance System using Raspberry Pi and Face\\nRecognition\\nDOI10.17148/IJARCCE.2017.64117\\nGarbage Level Monitoring System\\nInterests\\n• Competitive Programming\\n• Photography\\n• Sketching\\n• Reading/Writing on Quora\\n• Contributing to Open Source projects\\nNOVEMBER 3, 2019\\nOMKAR PATHAK · RÉSUMÉ\\n3\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydoc = nlp(text)\n",
        "for ent in mydoc.ents:\n",
        "    print(ent.text, \" - \", ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMn1IroKRf9B",
        "outputId": "a11d23d0-3421-4ee0-b4b1-74fa028e6213"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "July 2018 - Present\n",
            "• Responsible for implementing and managing an end-to-end CI/CD Pipeline with custom validations for Informatica migrations which\n",
            "brought migration time to 1.5 hours from  -  EXPERIENCE\n",
            "June 2018 - July 2018\n",
            "• Created RESTful apis\n",
            "• Tried my hands on Angular 5/6\n",
            "• Was responsible for Django backend development\n",
            "Propeluss\n",
            "Pune, Maharashtra, India\n",
            "DATA ENGINEERING INTERN\n",
            "October 2017 - January 2018\n",
            "• Wrote various automation scripts to scrape data from various websites.\n",
            "• Applied Natural Language Processing to articles scraped  -  EXPERIENCE\n",
            "July 2017 - September 2017\n",
            "• Published 4 articles for the topics such as Data Structures and Algorithms and Python\n",
            "Softtestlab Technologies\n",
            "Pune, Maharashtra, India\n",
            "WEB DEVELOPER INTERN\n",
            "June 2017 - July 2017\n",
            "• Was responsible for creating an internal project for the company using PHP and Laravel for testing purposes\n",
            "• Worked on a live project for creating closure reports using PHP and Excel\n",
            "Projects\n",
            "Pyresparser\n",
            "API/Python Package\n",
            "PERSONAL PROJECT\n",
            "July 2019 - Present\n",
            "• A simple resume parser used for extracting information from resumes\n",
            "• Extract information from thousands of resumes in just a few seconds\n",
            "• Author and maintainer of this project\n",
            "Garbage Level Monitoring System\n",
            "IoT\n",
            "TEAM PROJECT\n",
            "October 2017 - May 2018\n",
            "• To find a economical and smarter alternative to current garbage problems\n",
            "• Users can monitor levels of all garbage bins  -  EXPERIENCE\n",
            "July 2017 - Present\n",
            "• Author and maintainer of this project\n",
            "• An educational library to teach all the major algorithms\n",
            "• Got covered in Fosstack, FullStackFeed, Kleiber and Tagged under Hotest Github Project on ITCodeMonkey\n",
            "Smart Surveillance System using Raspberry Pi and Face Recognition\n",
            "IoT\n",
            "PERSONAL PROJECT\n",
            "January 2017 - February 2017\n",
            "• Face Recognition using OpenCV and Python\n",
            "• Raspberry Pi was used as the data server\n",
            "• User notified if any suspicious activity detected in real time\n",
            "Password Strength Evaluator using Machine Learning\n",
            "Machine Learning\n",
            "PERSONAL PROJECT\n",
            "March 2017\n",
            "• SVM algorithm used for training and classification\n",
            "• Flask framework used\n",
            "• Self-generated dataset\n",
            "Education\n",
            "Marathwada Mitra Mandal’s College of Engineering\n",
            "Pune, Maharashtra, India\n",
            "B.E. IN COMPUTER ENGINEERING\n",
            "2014 - 2018\n",
            "• Aggregate 74%\n",
            "Skills\n",
            "Programming Languages:\n",
            "Python, C, PHP, C++, Shell  -  EXPERIENCE\n",
            "Awards\n",
            "2018  -  SKILLS\n",
            "Quora Top Writer,\n",
            "India  -  SKILLS\n",
            "Prize, in an Hackathon organized by MIT  -  EDUCATION\n",
            "Best Paper Award, in National Level Conference on “Emerging Trends in Computing , Analytics\n",
            "and Security  -  SKILLS\n",
            "Mentor at GirlScript Summer of Code  -  SKILLS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4-GtkZYjRoRR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}